# Линейные и логистические модели: LASSO, обычная регрессия и метод Jaakkola–Jordan

Данный ноутбук содержит реализацию с нуля следующих моделей машинного обучения:

- **Линейная регрессия с L1-регуляризацией (LASSO)** через градиентный спуск  
- **Обычная линейная регрессия**  
- **Логистическая регрессия с аппроксимацией Jaakkola–Jordan**  
- **Сравнение точности с `sklearn.LogisticRegression`**

Цель — сравнить поведение и свойства моделей на синтетических и реальных данных, продемонстрировать разреженность в LASSO и аппроксимацию логистической функции.

---


## Ключевые особенности

- **LASSO** занулил 91 из 100 коэффициентов, выявив только важные признаки  
- **Обычная линейная регрессия** сохранила все веса, не осуществляя отбор  
- **Jaakkola–Jordan** позволил аппроксимировать логистическую функцию без прямого вычисления её градиента  
- Точность `LogisticRegression` и аппроксимации оказалась практически идентичной

---


